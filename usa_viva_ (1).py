# -*- coding: utf-8 -*-
"""usa viva .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WaGVV3QQCNSnU_uHzVQpRpow380I7Cq9
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

df.head()

df = pd.read_csv("us_perm_visas.csv")

df

df.tail()

df.sample(1)

print(df.columns.values)

df["case_no"].nunique()

df["case_number"].nunique()

casenumberimdex=df.columns.get_loc("case_number")
case_noindex=df.columns.get_loc("case_no")
casenumberlist=[]
for value in df.iloc[0:8679,casenumberindex]:
    casenumberlist.append(value)
for value in df.iloc[8679:143948,casenoindex]:
    casenumberlist.append(value)

df["caseno"]=casenumberlist

df.columns



df.drop(["case_number","case_no"],axis=1,inplace=True)

df.columns

df["case_status"].unique()

for value in df.case_status.unique():
  print(len(df[df["case_status"]==value]),"occurence of status {}".format(value))

for value in df.case_status.unique():
  print(len(df[df["case_status"]==value]), "occcurence of status {}".format(value))

df=df[df.case_status!="Withdrawn"]

df.shape



df.loc[df.case_status=="Certified-Expired","case_status"]="Certified"
df.case_status.value_counts()

df.shape

df.case_status.value_counts(normalize=True)*100

#drop all empty rows and columsn
df.dropna(axis=1,how="all",inplace=True)
df.dropna(axis=0,how="all",inplace=True )

df.shape

for column in df.columns:
  print(f"the missing value for{column}is{df[column].isnull().sum()}")

for columns in df.columns:
  print(f"the unique values for{columns}is {df[column].isnull().sum()}")

df["decision_date"]

df["decision_date"]=pd.DataFrame(df["decision_date"])

df["decision_date"]

df["year"]=df["decision_date"].dt.year

# Convert 'decision_date' to datetime objects if it's not already
df["decision_date"] = pd.to_datetime(df["decision_date"])

# Now you should be able to extract the year
df["year"] = df["decision_date"].dt.year

import pandas as pd

# Convert 'decision_date' to datetime
df["decision_date"] = pd.to_datetime(df["decision_date"])  # Convert to datetime

# Now you can extract the year
df["year"] = df["decision_date"].dt.year

df["year"]

sns.countplot(x="year",hue="case_status",data=df)

df["employer_city"].unique()

df["employer_city"].shape

df["employer_city"].value_counts()

df["emoloyer_city"]=df["employer_city"].str.upper()
df["employer_city"].value_counts()

sns.countplot(x="employer_city",hue="year",data=df,order=df.employer_city.value_counts().iloc[:10].index)



fix, ax = plt.subplots()
fix.set_size_inches(13.7,8.29)
sns.set_context("paper", rc={"font.size": 12, "axis.titlesize": 12, "axes.labelsize": 15})
sns.countplot(x="employer_city", hue="year", data=df, order=df.employer_city.value_counts().iloc[:10].index)
plt.xticks(rotation=65)
ax.set(xlabel="employer_city",ylabel="number of visa application")

#top 10 employers by visa application
top_emp=df['employer_name'].value_counts().head(10)
top_emp.plot(kind="bar",color="green")
for i,v in enumerate(top_emp):
  plt.text(i,v+10,str(v),ha="center",va="bottom",fontsize=10)

fix,ax=subplot()
fig.set_size_inches(13.7,18.3)
sns.set_context("paper",rc={"font.size:12,axes.titlesiz":12,"axes.labelsize":15})
sns.countplot(x="employer_city",hue="year",data=df,order=df.employer_city.value_counts().iloc[:10].index)

df["us_economic_sector"]

us_economic_counts={}
for value in df[ 'us_economic_sector'].dropna():
  if value  in us_economic_counts:
    us_economic_counts[value]+=1

  else:
      us_economic_counts[value]=1

us_economic_counts

usecollabels=[]
usecolvalues=[]
explode=(0.035,0,0,0,0,0,0,0,0,0)
for key,value in us_economic_counts.items():
  usecollabels.append(key)
  usecolvalues.append(value)

usecolvalues

usecollabels

plt.figure(figsize=(13,13))
plt.pie(usecolvalues[:10],labels=usecollabels[:10],explode=explode,autopct="%1.1f%%")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Setting plot parameters
plt.figure(figsize=(10.7, 7.27))

# Creating the count plot
sns.countplot(x='application_type', data=df, palette='GnBu_d', order=df['application_type'].value_counts().index[:10])

# Iterating over elements in "application_type" column and displaying counts above bars
for i, v in enumerate(df['application_type'].value_counts().head(10)):
    plt.text(i, v, str(v), ha='center', va='bottom')

# Setting labels
plt.xlabel('Application type')
plt.ylabel('Number of Visa applications')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Setting plot parameters
plt.figure(figsize=(10.7, 7.27))

# Creating the count plot
sns.countplot(x='application_type', data=df, palette='GnBu_d', order=df['application_type'].value_counts().index[:10])

# Iterating over elements in "application_type" column and displaying counts above bars
for i, v in enumerate(df['application_type'].value_counts().head(10)):
    plt.text(i, v, str(v), ha='center', va='bottom')

# Setting labels
plt.xlabel('Application type')
plt.ylabel('Number of Visa applications')
plt.show()

df['pw_job_title_'].value_counts()[:20]

df.columns

#Displaying percentage of non-null values for each feature
i = 0;
for col in df.columns:
    i = i+1;
    print (i-1,"Column: '{}'".format(col),"contains ", np.round(100*df[col].count()/len(df['case_status']),decimals=2),"% non-null values" )

i=0;
for col in df.columns:
  i=i+1
  print(i-1,"column:'{}'".format(col),"contain",np.round(100*df[col].count()/len(df["case_status"]),decimals=2),'%non-null values')

#Displaying percentage of non-null values for each feature
i = 0;
for col in df.columns:
    i = i+1;
    print (i-1,"Column: '{}'".format(col),"contains ", np.round(100*df[col].count()/len(df['case_status']),decimals=2),"% non-null values" )



df=df.loc[:,df.count()>=185908]
df.info()

df=df.loc[:,]

df.info()

df["case_status"]

df.loc[df.case_status=="Certified","case_status"]=1

df.loc[df.case_status=="Denied","case_status"]=0


#fill the missing value of emloyer status ,column with mode

df['employer_state']=df["employer_state"].fillna(df["employer_state"].mode()[0])

#Mapping from state name to abbreviation
state_abbrevs = {
    'Alabama': 'AL',
    'Alaska': 'AK',
    'Arizona': 'AZ',
    'Arkansas': 'AR',
    'California': 'CA',
    'Colorado': 'CO',
    'Connecticut': 'CT',
    'Delaware': 'DE',
    'Florida': 'FL',
    'Georgia': 'GA',
    'Hawaii': 'HI',
    'Idaho': 'ID',
    'Illinois': 'IL',
    'Indiana': 'IN',
    'Iowa': 'IA',
    'Kansas': 'KS',
    'Kentucky': 'KY',
    'Louisiana': 'LA',
    'Maine': 'ME',
    'Maryland': 'MD',
    'Massachusetts': 'MA',
    'Michigan': 'MI',
    'Minnesota': 'MN',
    'Mississippi': 'MS',
    'Missouri': 'MO',
    'Montana': 'MT',
    'Nebraska': 'NE',
    'Nevada': 'NV',
    'New Hampshire': 'NH',
    'New Jersey': 'NJ',
    'New Mexico': 'NM',
    'New York': 'NY',
    'North Carolina': 'NC',
    'North Dakota': 'ND',
    'Ohio': 'OH',
    'Oklahoma': 'OK',
    'Oregon': 'OR',
    'Pennsylvania': 'PA',
    'Rhode Island': 'RI',
    'South Carolina': 'SC',
    'South Dakota': 'SD',
    'Tennessee': 'TN',
    'Texas': 'TX',
    'Utah': 'UT',
    'Vermont': 'VT',
    'Virginia': 'VA',
    'Washington': 'WA',
    'West Virginia': 'WV',
    'Wisconsin': 'WI',
    'Wyoming': 'WY',
    'Northern Mariana Islands':'MP',
    'Palau': 'PW',
    'Puerto Rico': 'PR',
    'Virgin Islands': 'VI',
    'District of Columbia': 'DC'
}


us_state_addrev={k.upper():v for k ,v in state_abbrevs.items()}
df["employer_state"].replace(us_state_abbrev,inplace=True)

df["pw_soc_code"]=df["pw_soc_code"].str.replace('.',"")
df["pw_soc_code"]=df["pw_soc_code"].str.replace('-',"")
df["pw_soc_code"]=df["pw_soc_code"].astype(str).str[0:6]
df["pw_soc_code"].value_counts()

df.loc[df["pw_soc_code"]=="nan",'pw_soc_code']=df["pw_soc_code"].mode()[0]

df.loc[df["pw_soc_code"]=="None","pw_soc_code"]=df["pw_soc_code"].mode()[0]

df["pw_soc_code"].astype(int)

# Convert the column containing numerical values with commas to numeric format



df["pw_amount_9089"]=df["pw_amount_9089"].str.replace(',',"").astype(float)
median_pw_amount=df["pw_amount_9089"].median()
df["pw_amount_9809"].fillna(median_pw_amount,inplace=True)
print(df.isnull().sum())

df.columns

df.info()

df.columns.values

# Convert the column containing numerical values with commas to numeric format
df['pw_amount_9089'] = df['pw_amount_9089'].str.replace(',', '').astype(float)

# Now, you can replace null values in the numerical column with the median
median_pw_amount = df['pw_amount_9089'].median()
df['pw_amount_9089'].fillna(median_pw_amount, inplace=True)

# Verify that there are no more null values
print(df.isnull().sum())

from sklearn.preprocessing import LabelEncoder
categorical_variables={}
for col in df.columns:
  cat_var_name="cat"